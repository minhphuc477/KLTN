{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b79fb9be",
   "metadata": {},
   "source": [
    "# H-MOLQD Kaggle Training\n",
    "\n",
    "Production-ready training notebook with robust checkpoint management.\n",
    "\n",
    "**Features:**\n",
    "- âœ… Automatic checkpoint saving every N epochs\n",
    "- âœ… Auto-resume from latest checkpoint\n",
    "- âœ… Manual resume from specific checkpoint\n",
    "- âœ… Save optimizer + scheduler state\n",
    "- âœ… Save training metrics history\n",
    "- âœ… Handle interruptions gracefully\n",
    "- âœ… Export final models & results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea45f21",
   "metadata": {},
   "source": [
    "## 1. Installation & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813b1831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q networkx torch torchvision numpy matplotlib tqdm\n",
    "\n",
    "# Optional: Uncomment to download dataset\n",
    "# !kaggle datasets download -d yourusername/zelda-vglc-data\n",
    "# !unzip -q zelda-vglc-data.zip -d /kaggle/input/\n",
    "\n",
    "print(\"âœ… Installation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dccf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e369fb",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48616102",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    # Training parameters\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    'checkpoint_every': 5,  # Save every N epochs\n",
    "    \n",
    "    # Model parameters\n",
    "    'latent_dim': 64,\n",
    "    'num_embeddings': 512,\n",
    "    'num_timesteps': 1000,\n",
    "    'embedding_dim': 256,\n",
    "    \n",
    "    # Paths\n",
    "    'data_dir': '/kaggle/input/zelda-vglc-data',\n",
    "    'checkpoint_dir': '/kaggle/working/checkpoints',\n",
    "    'output_dir': '/kaggle/working/outputs',\n",
    "    \n",
    "    # Resume\n",
    "    'resume_from': None,  # Set to checkpoint path to manually resume\n",
    "    'auto_resume': True,   # Automatically resume from latest if exists\n",
    "    \n",
    "    # Mixed precision training\n",
    "    'use_amp': torch.cuda.is_available(),\n",
    "    \n",
    "    # Logging\n",
    "    'log_every': 10,  # Log every N batches\n",
    "    'val_every': 1,   # Validate every N epochs\n",
    "}\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(CONFIG['checkpoint_dir'], exist_ok=True)\n",
    "os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
    "\n",
    "# Save config\n",
    "with open(f\"{CONFIG['output_dir']}/config.json\", 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=2)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(json.dumps(CONFIG, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0039f75",
   "metadata": {},
   "source": [
    "## 3. Checkpoint Management System\n",
    "\n",
    "**Robust checkpoint manager with:**\n",
    "- Automatic saving every N epochs\n",
    "- Resume from latest or specific checkpoint\n",
    "- Save full training state (model, optimizer, scheduler, metrics)\n",
    "- Handle interruptions gracefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db69190",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckpointManager:\n",
    "    \"\"\"\n",
    "    Manages checkpoint saving and loading for Kaggle training.\n",
    "    \n",
    "    Features:\n",
    "    - Automatic checkpoint saving every N epochs\n",
    "    - Resume from latest checkpoint\n",
    "    - Save optimizer state, scheduler state, metrics\n",
    "    - Handle interruptions gracefully\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, checkpoint_dir, save_every=5):\n",
    "        self.checkpoint_dir = Path(checkpoint_dir)\n",
    "        self.checkpoint_dir.mkdir(exist_ok=True, parents=True)\n",
    "        self.save_every = save_every\n",
    "        self.best_metric = float('inf')  # Lower is better\n",
    "    \n",
    "    def save_checkpoint(\n",
    "        self,\n",
    "        epoch,\n",
    "        model,\n",
    "        optimizer,\n",
    "        scheduler=None,\n",
    "        metrics=None,\n",
    "        extra_state=None,\n",
    "        is_best=False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Save training checkpoint.\n",
    "        \n",
    "        Args:\n",
    "            epoch: Current epoch number\n",
    "            model: Model or dict of models\n",
    "            optimizer: Optimizer or dict of optimizers\n",
    "            scheduler: LR scheduler (optional)\n",
    "            metrics: Dict of training metrics\n",
    "            extra_state: Any additional state to save\n",
    "            is_best: Whether this is the best checkpoint\n",
    "        \"\"\"\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'metrics': metrics or {},\n",
    "            'extra_state': extra_state or {},\n",
    "        }\n",
    "        \n",
    "        # Save model(s)\n",
    "        if isinstance(model, dict):\n",
    "            checkpoint['model_state_dict'] = {\n",
    "                name: m.state_dict() for name, m in model.items()\n",
    "            }\n",
    "        else:\n",
    "            checkpoint['model_state_dict'] = model.state_dict()\n",
    "        \n",
    "        # Save optimizer(s)\n",
    "        if isinstance(optimizer, dict):\n",
    "            checkpoint['optimizer_state_dict'] = {\n",
    "                name: opt.state_dict() for name, opt in optimizer.items()\n",
    "            }\n",
    "        else:\n",
    "            checkpoint['optimizer_state_dict'] = optimizer.state_dict()\n",
    "        \n",
    "        # Save scheduler\n",
    "        if scheduler is not None:\n",
    "            if isinstance(scheduler, dict):\n",
    "                checkpoint['scheduler_state_dict'] = {\n",
    "                    name: sch.state_dict() for name, sch in scheduler.items()\n",
    "                }\n",
    "            else:\n",
    "                checkpoint['scheduler_state_dict'] = scheduler.state_dict()\n",
    "        \n",
    "        # Save regular checkpoint\n",
    "        checkpoint_path = self.checkpoint_dir / f'checkpoint_epoch_{epoch}.pt'\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        \n",
    "        # Save \"latest\" pointer\n",
    "        latest_path = self.checkpoint_dir / 'checkpoint_latest.pt'\n",
    "        torch.save(checkpoint, latest_path)\n",
    "        \n",
    "        # Save \"best\" if applicable\n",
    "        if is_best:\n",
    "            best_path = self.checkpoint_dir / 'checkpoint_best.pt'\n",
    "            torch.save(checkpoint, best_path)\n",
    "            print(f\"ðŸ’Ž Best checkpoint saved (epoch {epoch})\")\n",
    "        \n",
    "        print(f\"âœ… Checkpoint saved: epoch {epoch}\")\n",
    "        \n",
    "        return checkpoint_path\n",
    "    \n",
    "    def load_checkpoint(self, checkpoint_path=None):\n",
    "        \"\"\"\n",
    "        Load checkpoint.\n",
    "        \n",
    "        Args:\n",
    "            checkpoint_path: Specific checkpoint to load, or None for latest\n",
    "        \n",
    "        Returns:\n",
    "            checkpoint dict or None if no checkpoint found\n",
    "        \"\"\"\n",
    "        if checkpoint_path is None:\n",
    "            # Try to load latest\n",
    "            latest_path = self.checkpoint_dir / 'checkpoint_latest.pt'\n",
    "            if latest_path.exists():\n",
    "                checkpoint_path = latest_path\n",
    "            else:\n",
    "                # Find latest numbered checkpoint\n",
    "                checkpoints = sorted(self.checkpoint_dir.glob('checkpoint_epoch_*.pt'))\n",
    "                if checkpoints:\n",
    "                    checkpoint_path = checkpoints[-1]\n",
    "                else:\n",
    "                    print(\"No checkpoint found - starting from scratch\")\n",
    "                    return None\n",
    "        \n",
    "        checkpoint_path = Path(checkpoint_path)\n",
    "        if not checkpoint_path.exists():\n",
    "            print(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "            return None\n",
    "        \n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        print(f\"âœ… Loaded checkpoint from epoch {checkpoint['epoch']}\")\n",
    "        print(f\"   Saved at: {checkpoint['timestamp']}\")\n",
    "        \n",
    "        return checkpoint\n",
    "    \n",
    "    def restore_training_state(\n",
    "        self,\n",
    "        checkpoint,\n",
    "        model,\n",
    "        optimizer,\n",
    "        scheduler=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Restore training state from checkpoint.\n",
    "        \n",
    "        Args:\n",
    "            checkpoint: Loaded checkpoint dict\n",
    "            model: Model or dict of models\n",
    "            optimizer: Optimizer or dict of optimizers\n",
    "            scheduler: LR scheduler (optional)\n",
    "        \n",
    "        Returns:\n",
    "            start_epoch: Epoch to resume from\n",
    "        \"\"\"\n",
    "        # Restore model(s)\n",
    "        if isinstance(model, dict):\n",
    "            for name, m in model.items():\n",
    "                m.load_state_dict(checkpoint['model_state_dict'][name])\n",
    "                print(f\"   Restored model: {name}\")\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            print(\"   Restored model\")\n",
    "        \n",
    "        # Restore optimizer(s)\n",
    "        if isinstance(optimizer, dict):\n",
    "            for name, opt in optimizer.items():\n",
    "                opt.load_state_dict(checkpoint['optimizer_state_dict'][name])\n",
    "                print(f\"   Restored optimizer: {name}\")\n",
    "        else:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            print(\"   Restored optimizer\")\n",
    "        \n",
    "        # Restore scheduler\n",
    "        if scheduler is not None and 'scheduler_state_dict' in checkpoint:\n",
    "            if isinstance(scheduler, dict):\n",
    "                for name, sch in scheduler.items():\n",
    "                    sch.load_state_dict(checkpoint['scheduler_state_dict'][name])\n",
    "                    print(f\"   Restored scheduler: {name}\")\n",
    "            else:\n",
    "                scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "                print(\"   Restored scheduler\")\n",
    "        \n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print(f\"\\nðŸš€ Resuming from epoch {start_epoch}\")\n",
    "        \n",
    "        return start_epoch\n",
    "    \n",
    "    def should_save(self, epoch):\n",
    "        \"\"\"Check if should save checkpoint this epoch.\"\"\"\n",
    "        return (epoch + 1) % self.save_every == 0\n",
    "\n",
    "print(\"âœ… CheckpointManager class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103771a4",
   "metadata": {},
   "source": [
    "## 4. Data Loading\n",
    "\n",
    "Load VGLC Zelda dungeon data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80950df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vglc_data(data_dir):\n",
    "    \"\"\"\n",
    "    Load VGLC Zelda dungeon data.\n",
    "    \n",
    "    TODO: Implement actual data loading based on your data format.\n",
    "    This is a placeholder that should be replaced with:\n",
    "    - Load level files from data_dir\n",
    "    - Parse dungeon structures\n",
    "    - Create train/val splits\n",
    "    - Create DataLoaders\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from: {data_dir}\")\n",
    "    \n",
    "    # Placeholder implementation\n",
    "    # Replace with actual data loading code\n",
    "    train_data = []\n",
    "    val_data = []\n",
    "    \n",
    "    # Example structure (replace with actual loading):\n",
    "    # data_path = Path(data_dir)\n",
    "    # for level_file in data_path.glob('*.txt'):\n",
    "    #     level = parse_level(level_file)\n",
    "    #     train_data.append(level)\n",
    "    \n",
    "    print(f\"âœ… Loaded {len(train_data)} training samples\")\n",
    "    print(f\"âœ… Loaded {len(val_data)} validation samples\")\n",
    "    \n",
    "    return {\n",
    "        'train': train_data,\n",
    "        'val': val_data\n",
    "    }\n",
    "\n",
    "# Load data\n",
    "# data = load_vglc_data(CONFIG['data_dir'])\n",
    "\n",
    "# Create DataLoaders\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     data['train'],\n",
    "#     batch_size=CONFIG['batch_size'],\n",
    "#     shuffle=True,\n",
    "#     num_workers=2,\n",
    "#     pin_memory=True\n",
    "# )\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#     data['val'],\n",
    "#     batch_size=CONFIG['batch_size'],\n",
    "#     shuffle=False,\n",
    "#     num_workers=2,\n",
    "#     pin_memory=True\n",
    "# )\n",
    "\n",
    "print(\"âœ… Data loading configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257e3443",
   "metadata": {},
   "source": [
    "## 5. Model Initialization\n",
    "\n",
    "Initialize VQ-VAE, Diffusion, and LogicNet models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a2d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import your actual models\n",
    "# from src.core.vqvae import SemanticVQVAE\n",
    "# from src.core.latent_diffusion import LatentDiffusionModel\n",
    "# from src.core.logic_net import LogicNet\n",
    "\n",
    "# Initialize models\n",
    "# vqvae = SemanticVQVAE(\n",
    "#     num_embeddings=CONFIG['num_embeddings'],\n",
    "#     embedding_dim=CONFIG['embedding_dim'],\n",
    "#     latent_dim=CONFIG['latent_dim']\n",
    "# ).to(device)\n",
    "\n",
    "# diffusion = LatentDiffusionModel(\n",
    "#     latent_dim=CONFIG['latent_dim'],\n",
    "#     num_timesteps=CONFIG['num_timesteps']\n",
    "# ).to(device)\n",
    "\n",
    "# logic_net = LogicNet(\n",
    "#     input_dim=CONFIG['latent_dim']\n",
    "# ).to(device)\n",
    "\n",
    "# Placeholder model for demonstration\n",
    "class PlaceholderModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Linear(64, 64)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = PlaceholderModel().to(device)\n",
    "\n",
    "# Optimizers\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=CONFIG['num_epochs']\n",
    ")\n",
    "\n",
    "# Mixed precision scaler\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=CONFIG['use_amp'])\n",
    "\n",
    "print(\"âœ… Models initialized\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5716c94",
   "metadata": {},
   "source": [
    "## 6. Resume from Checkpoint\n",
    "\n",
    "Automatically resume from latest checkpoint if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d899e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize checkpoint manager\n",
    "checkpoint_manager = CheckpointManager(\n",
    "    CONFIG['checkpoint_dir'],\n",
    "    save_every=CONFIG['checkpoint_every']\n",
    ")\n",
    "\n",
    "start_epoch = 0\n",
    "training_history = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Try to resume\n",
    "checkpoint = None\n",
    "if CONFIG['resume_from'] is not None:\n",
    "    # Manual resume from specific checkpoint\n",
    "    checkpoint = checkpoint_manager.load_checkpoint(CONFIG['resume_from'])\n",
    "elif CONFIG['auto_resume']:\n",
    "    # Auto-resume from latest\n",
    "    checkpoint = checkpoint_manager.load_checkpoint()\n",
    "\n",
    "if checkpoint is not None:\n",
    "    # Restore training state\n",
    "    start_epoch = checkpoint_manager.restore_training_state(\n",
    "        checkpoint,\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "    \n",
    "    # Restore metrics\n",
    "    training_history = checkpoint.get('metrics', {}).get('history', [])\n",
    "    best_val_loss = checkpoint.get('metrics', {}).get('best_val_loss', float('inf'))\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Previous metrics:\")\n",
    "    print(f\"   Best val loss: {best_val_loss:.4f}\")\n",
    "    print(f\"   Training history: {len(training_history)} epochs\")\n",
    "else:\n",
    "    print(\"\\nðŸ†• Starting fresh training\")\n",
    "\n",
    "print(f\"\\nðŸ“… Training plan: epochs {start_epoch} â†’ {CONFIG['num_epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e5cc6f",
   "metadata": {},
   "source": [
    "## 7. Training Loop\n",
    "\n",
    "Main training loop with progress tracking and checkpoint saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1bc68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, scheduler, scaler, epoch):\n",
    "    \"\"\"\n",
    "    Train for one epoch.\n",
    "    \n",
    "    TODO: Replace with actual training logic.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    # Placeholder implementation\n",
    "    # Replace with actual training loop\n",
    "    total_loss = 0.0\n",
    "    num_batches = 100  # Placeholder\n",
    "    \n",
    "    pbar = tqdm(range(num_batches), desc=f\"Epoch {epoch}\")\n",
    "    for batch_idx in pbar:\n",
    "        # Simulate training step\n",
    "        loss = torch.rand(1).item()\n",
    "        total_loss += loss\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss:.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    return {\n",
    "        'epoch': epoch,\n",
    "        'train_loss': avg_loss,\n",
    "        'lr': optimizer.param_groups[0]['lr']\n",
    "    }\n",
    "\n",
    "def validate(model, val_loader, epoch):\n",
    "    \"\"\"\n",
    "    Validate the model.\n",
    "    \n",
    "    TODO: Replace with actual validation logic.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Placeholder implementation\n",
    "    val_loss = torch.rand(1).item()\n",
    "    \n",
    "    return {\n",
    "        'val_loss': val_loss\n",
    "    }\n",
    "\n",
    "print(\"âœ… Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸš€ STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for epoch in range(start_epoch, CONFIG['num_epochs']):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ðŸ“… Epoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Train\n",
    "    train_metrics = train_epoch(\n",
    "        model=model,\n",
    "        train_loader=None,  # Replace with actual loader\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        scaler=scaler,\n",
    "        epoch=epoch\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    if (epoch + 1) % CONFIG['val_every'] == 0:\n",
    "        val_metrics = validate(\n",
    "            model=model,\n",
    "            val_loader=None,  # Replace with actual loader\n",
    "            epoch=epoch\n",
    "        )\n",
    "        train_metrics.update(val_metrics)\n",
    "    \n",
    "    # Log metrics\n",
    "    print(f\"\\nðŸ“Š Metrics:\")\n",
    "    print(f\"   Train Loss: {train_metrics['train_loss']:.4f}\")\n",
    "    if 'val_loss' in train_metrics:\n",
    "        print(f\"   Val Loss:   {train_metrics['val_loss']:.4f}\")\n",
    "    print(f\"   LR:         {train_metrics['lr']:.6f}\")\n",
    "    \n",
    "    # Update best model\n",
    "    is_best = False\n",
    "    if 'val_loss' in train_metrics and train_metrics['val_loss'] < best_val_loss:\n",
    "        best_val_loss = train_metrics['val_loss']\n",
    "        is_best = True\n",
    "        print(f\"   ðŸ’Ž New best model! (val_loss: {best_val_loss:.4f})\")\n",
    "    \n",
    "    # Save metrics\n",
    "    training_history.append(train_metrics)\n",
    "    \n",
    "    # Save checkpoint\n",
    "    if checkpoint_manager.should_save(epoch) or is_best:\n",
    "        checkpoint_manager.save_checkpoint(\n",
    "            epoch=epoch,\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            metrics={\n",
    "                'current_train_loss': train_metrics['train_loss'],\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'history': training_history\n",
    "            },\n",
    "            extra_state={\n",
    "                'config': CONFIG\n",
    "            },\n",
    "            is_best=is_best\n",
    "        )\n",
    "    \n",
    "    # Step scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBest validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57eb0b3",
   "metadata": {},
   "source": [
    "## 8. Save Final Models\n",
    "\n",
    "Export final models and training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b3626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final checkpoint\n",
    "final_checkpoint_path = checkpoint_manager.save_checkpoint(\n",
    "    epoch=CONFIG['num_epochs'] - 1,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    metrics={\n",
    "        'final_train_loss': training_history[-1]['train_loss'],\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'history': training_history\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Final checkpoint saved: {final_checkpoint_path}\")\n",
    "\n",
    "# Export final model weights\n",
    "torch.save(model.state_dict(), f\"{CONFIG['output_dir']}/model_final.pt\")\n",
    "\n",
    "# Export training history\n",
    "with open(f\"{CONFIG['output_dir']}/training_history.json\", 'w') as f:\n",
    "    json.dump(training_history, f, indent=2)\n",
    "\n",
    "print(\"âœ… Model weights exported\")\n",
    "print(\"âœ… Training history exported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fea476",
   "metadata": {},
   "source": [
    "## 9. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ea457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "epochs = [m['epoch'] for m in training_history]\n",
    "train_losses = [m['train_loss'] for m in training_history]\n",
    "val_losses = [m.get('val_loss', None) for m in training_history]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss curves\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Train Loss', linewidth=2)\n",
    "if any(v is not None for v in val_losses):\n",
    "    val_losses_clean = [v for v in val_losses if v is not None]\n",
    "    val_epochs = [e for e, v in zip(epochs, val_losses) if v is not None]\n",
    "    plt.plot(val_epochs, val_losses_clean, label='Val Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Progress')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "plt.subplot(1, 2, 2)\n",
    "lrs = [m['lr'] for m in training_history]\n",
    "plt.plot(epochs, lrs, linewidth=2, color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CONFIG['output_dir']}/training_curves.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Training curves saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7875fc9",
   "metadata": {},
   "source": [
    "## 10. Generate Sample Dungeons\n",
    "\n",
    "Generate and visualize sample outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93565ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement actual dungeon generation\n",
    "# def generate_dungeons(model, num_samples=5):\n",
    "#     model.eval()\n",
    "#     samples = []\n",
    "#     with torch.no_grad():\n",
    "#         for i in range(num_samples):\n",
    "#             sample = model.generate()\n",
    "#             samples.append(sample)\n",
    "#     return samples\n",
    "\n",
    "# samples = generate_dungeons(model, num_samples=5)\n",
    "\n",
    "# for i, sample in enumerate(samples):\n",
    "#     plt.figure(figsize=(10, 14))\n",
    "#     plt.imshow(sample, cmap='viridis')\n",
    "#     plt.title(f\"Generated Dungeon {i+1}\")\n",
    "#     plt.axis('off')\n",
    "#     plt.savefig(f\"{CONFIG['output_dir']}/sample_{i+1}.png\", dpi=150, bbox_inches='tight')\n",
    "#     plt.show()\n",
    "\n",
    "print(\"âœ… Sample generation placeholder - implement actual generation logic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f7db79",
   "metadata": {},
   "source": [
    "## 11. Create Submission Archive\n",
    "\n",
    "Package all outputs for easy download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a9447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Create zip of outputs\n",
    "zip_path = '/kaggle/working/h_molqd_outputs.zip'\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    # Add checkpoints\n",
    "    checkpoint_dir = Path(CONFIG['checkpoint_dir'])\n",
    "    if checkpoint_dir.exists():\n",
    "        for checkpoint_file in checkpoint_dir.glob('*.pt'):\n",
    "            zipf.write(checkpoint_file, f\"checkpoints/{checkpoint_file.name}\")\n",
    "            print(f\"   Added: checkpoints/{checkpoint_file.name}\")\n",
    "    \n",
    "    # Add outputs\n",
    "    output_dir = Path(CONFIG['output_dir'])\n",
    "    if output_dir.exists():\n",
    "        for output_file in output_dir.glob('*'):\n",
    "            if output_file.is_file():\n",
    "                zipf.write(output_file, f\"outputs/{output_file.name}\")\n",
    "                print(f\"   Added: outputs/{output_file.name}\")\n",
    "\n",
    "# Get file size\n",
    "zip_size_mb = Path(zip_path).stat().st_size / (1024 * 1024)\n",
    "\n",
    "print(f\"\\nâœ… Created submission archive: {zip_path}\")\n",
    "print(f\"   Size: {zip_size_mb:.2f} MB\")\n",
    "print(\"\\nðŸ“¦ Download this file from Kaggle output panel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e9966c",
   "metadata": {},
   "source": [
    "## Training Complete! ðŸŽ‰\n",
    "\n",
    "### What's saved:\n",
    "- âœ… Checkpoints (every 5 epochs + best model)\n",
    "- âœ… Final model weights\n",
    "- âœ… Training history & metrics\n",
    "- âœ… Training curves visualization\n",
    "- âœ… Complete archive (h_molqd_outputs.zip)\n",
    "\n",
    "### Next steps:\n",
    "1. Download `h_molqd_outputs.zip` from Kaggle output\n",
    "2. Extract checkpoints for inference\n",
    "3. Analyze training curves\n",
    "4. Generate dungeons using best checkpoint\n",
    "\n",
    "### To resume training:\n",
    "```python\n",
    "# Automatic resume (loads latest)\n",
    "CONFIG['auto_resume'] = True\n",
    "\n",
    "# Or manual resume (loads specific checkpoint)\n",
    "CONFIG['resume_from'] = '/kaggle/working/checkpoints/checkpoint_epoch_50.pt'\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
