{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db6b8c2",
   "metadata": {},
   "source": [
    "# Checkpoint Manager Test\n",
    "\n",
    "Quick test to verify checkpoint save/load functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3fcc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"‚úÖ Imports loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f95fe5c",
   "metadata": {},
   "source": [
    "## CheckpointManager Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6bbb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckpointManager:\n",
    "    \"\"\"Checkpoint manager for testing.\"\"\"\n",
    "    \n",
    "    def __init__(self, checkpoint_dir, save_every=5):\n",
    "        self.checkpoint_dir = Path(checkpoint_dir)\n",
    "        self.checkpoint_dir.mkdir(exist_ok=True, parents=True)\n",
    "        self.save_every = save_every\n",
    "    \n",
    "    def save_checkpoint(self, epoch, model, optimizer, scheduler=None, metrics=None, extra_state=None, is_best=False):\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'metrics': metrics or {},\n",
    "            'extra_state': extra_state or {},\n",
    "        }\n",
    "        \n",
    "        if isinstance(model, dict):\n",
    "            checkpoint['model_state_dict'] = {name: m.state_dict() for name, m in model.items()}\n",
    "        else:\n",
    "            checkpoint['model_state_dict'] = model.state_dict()\n",
    "        \n",
    "        if isinstance(optimizer, dict):\n",
    "            checkpoint['optimizer_state_dict'] = {name: opt.state_dict() for name, opt in optimizer.items()}\n",
    "        else:\n",
    "            checkpoint['optimizer_state_dict'] = optimizer.state_dict()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            if isinstance(scheduler, dict):\n",
    "                checkpoint['scheduler_state_dict'] = {name: sch.state_dict() for name, sch in scheduler.items()}\n",
    "            else:\n",
    "                checkpoint['scheduler_state_dict'] = scheduler.state_dict()\n",
    "        \n",
    "        checkpoint_path = self.checkpoint_dir / f'checkpoint_epoch_{epoch}.pt'\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        \n",
    "        latest_path = self.checkpoint_dir / 'checkpoint_latest.pt'\n",
    "        torch.save(checkpoint, latest_path)\n",
    "        \n",
    "        if is_best:\n",
    "            best_path = self.checkpoint_dir / 'checkpoint_best.pt'\n",
    "            torch.save(checkpoint, best_path)\n",
    "        \n",
    "        return checkpoint_path\n",
    "    \n",
    "    def load_checkpoint(self, checkpoint_path=None):\n",
    "        if checkpoint_path is None:\n",
    "            latest_path = self.checkpoint_dir / 'checkpoint_latest.pt'\n",
    "            if latest_path.exists():\n",
    "                checkpoint_path = latest_path\n",
    "            else:\n",
    "                checkpoints = sorted(self.checkpoint_dir.glob('checkpoint_epoch_*.pt'))\n",
    "                if checkpoints:\n",
    "                    checkpoint_path = checkpoints[-1]\n",
    "                else:\n",
    "                    return None\n",
    "        \n",
    "        checkpoint_path = Path(checkpoint_path)\n",
    "        if not checkpoint_path.exists():\n",
    "            return None\n",
    "        \n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        return checkpoint\n",
    "    \n",
    "    def restore_training_state(self, checkpoint, model, optimizer, scheduler=None):\n",
    "        if isinstance(model, dict):\n",
    "            for name, m in model.items():\n",
    "                m.load_state_dict(checkpoint['model_state_dict'][name])\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        if isinstance(optimizer, dict):\n",
    "            for name, opt in optimizer.items():\n",
    "                opt.load_state_dict(checkpoint['optimizer_state_dict'][name])\n",
    "        else:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "        if scheduler is not None and 'scheduler_state_dict' in checkpoint:\n",
    "            if isinstance(scheduler, dict):\n",
    "                for name, sch in scheduler.items():\n",
    "                    sch.load_state_dict(checkpoint['scheduler_state_dict'][name])\n",
    "            else:\n",
    "                scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        \n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        return start_epoch\n",
    "\n",
    "print(\"‚úÖ CheckpointManager defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1034243e",
   "metadata": {},
   "source": [
    "## Test 1: Basic Save/Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e0c6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "test_dir = Path('/tmp/test_checkpoints')\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "\n",
    "manager = CheckpointManager(test_dir, save_every=1)\n",
    "\n",
    "# Create dummy model\n",
    "model = torch.nn.Linear(10, 10)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "\n",
    "print(\"‚úÖ Test setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c6a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "print(\"\\nüìù Saving checkpoint...\")\n",
    "checkpoint_path = manager.save_checkpoint(\n",
    "    epoch=5,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    metrics={'loss': 0.123, 'accuracy': 0.95}\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "# Verify files exist\n",
    "assert (test_dir / 'checkpoint_epoch_5.pt').exists(), \"Epoch checkpoint not found\"\n",
    "assert (test_dir / 'checkpoint_latest.pt').exists(), \"Latest checkpoint not found\"\n",
    "print(\"‚úÖ Checkpoint files verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a52c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "print(\"\\nüìñ Loading checkpoint...\")\n",
    "checkpoint = manager.load_checkpoint()\n",
    "\n",
    "assert checkpoint is not None, \"Checkpoint not loaded\"\n",
    "assert checkpoint['epoch'] == 5, f\"Wrong epoch: {checkpoint['epoch']}\"\n",
    "assert checkpoint['metrics']['loss'] == 0.123, \"Wrong loss value\"\n",
    "assert checkpoint['metrics']['accuracy'] == 0.95, \"Wrong accuracy value\"\n",
    "\n",
    "print(\"‚úÖ Checkpoint loaded successfully\")\n",
    "print(f\"   Epoch: {checkpoint['epoch']}\")\n",
    "print(f\"   Loss: {checkpoint['metrics']['loss']}\")\n",
    "print(f\"   Accuracy: {checkpoint['metrics']['accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50dc935",
   "metadata": {},
   "source": [
    "## Test 2: Resume Training State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6fb41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new model/optimizer (simulating restart)\n",
    "new_model = torch.nn.Linear(10, 10)\n",
    "new_optimizer = torch.optim.Adam(new_model.parameters())\n",
    "new_scheduler = torch.optim.lr_scheduler.StepLR(new_optimizer, step_size=1)\n",
    "\n",
    "# Restore state\n",
    "print(\"\\nüîÑ Restoring training state...\")\n",
    "start_epoch = manager.restore_training_state(\n",
    "    checkpoint,\n",
    "    model=new_model,\n",
    "    optimizer=new_optimizer,\n",
    "    scheduler=new_scheduler\n",
    ")\n",
    "\n",
    "assert start_epoch == 6, f\"Wrong start epoch: {start_epoch}\"\n",
    "print(f\"‚úÖ Training state restored\")\n",
    "print(f\"   Next epoch: {start_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c02272",
   "metadata": {},
   "source": [
    "## Test 3: Best Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b55e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best checkpoint\n",
    "print(\"\\nüíé Saving best checkpoint...\")\n",
    "manager.save_checkpoint(\n",
    "    epoch=10,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    metrics={'loss': 0.050, 'accuracy': 0.98},\n",
    "    is_best=True\n",
    ")\n",
    "\n",
    "assert (test_dir / 'checkpoint_best.pt').exists(), \"Best checkpoint not found\"\n",
    "print(\"‚úÖ Best checkpoint saved\")\n",
    "\n",
    "# Verify best checkpoint\n",
    "best_checkpoint = torch.load(test_dir / 'checkpoint_best.pt')\n",
    "assert best_checkpoint['epoch'] == 10, \"Wrong best epoch\"\n",
    "assert best_checkpoint['metrics']['loss'] == 0.050, \"Wrong best loss\"\n",
    "print(f\"‚úÖ Best checkpoint verified (epoch {best_checkpoint['epoch']}, loss {best_checkpoint['metrics']['loss']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf32ddd",
   "metadata": {},
   "source": [
    "## Test 4: Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8cee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with multiple models\n",
    "print(\"\\nüîÄ Testing multiple models...\")\n",
    "\n",
    "models = {\n",
    "    'encoder': torch.nn.Linear(10, 5),\n",
    "    'decoder': torch.nn.Linear(5, 10)\n",
    "}\n",
    "\n",
    "optimizers = {\n",
    "    'encoder': torch.optim.Adam(models['encoder'].parameters()),\n",
    "    'decoder': torch.optim.Adam(models['decoder'].parameters())\n",
    "}\n",
    "\n",
    "# Save\n",
    "manager.save_checkpoint(\n",
    "    epoch=15,\n",
    "    model=models,\n",
    "    optimizer=optimizers,\n",
    "    metrics={'loss': 0.030}\n",
    ")\n",
    "\n",
    "# Load\n",
    "checkpoint = manager.load_checkpoint()\n",
    "assert 'encoder' in checkpoint['model_state_dict'], \"Encoder state not found\"\n",
    "assert 'decoder' in checkpoint['model_state_dict'], \"Decoder state not found\"\n",
    "\n",
    "print(\"‚úÖ Multiple models test passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2bc548",
   "metadata": {},
   "source": [
    "## Test Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9892a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ ALL TESTS PASSED!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n‚úÖ Verified functionality:\")\n",
    "print(\"   ‚Ä¢ Save checkpoint\")\n",
    "print(\"   ‚Ä¢ Load checkpoint\")\n",
    "print(\"   ‚Ä¢ Resume training state\")\n",
    "print(\"   ‚Ä¢ Best checkpoint tracking\")\n",
    "print(\"   ‚Ä¢ Multiple models support\")\n",
    "print(\"   ‚Ä¢ Optimizer state persistence\")\n",
    "print(\"   ‚Ä¢ Scheduler state persistence\")\n",
    "print(\"   ‚Ä¢ Metrics tracking\")\n",
    "\n",
    "# Cleanup\n",
    "import shutil\n",
    "shutil.rmtree(test_dir, ignore_errors=True)\n",
    "print(\"\\nüßπ Test directory cleaned up\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
